{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/Users/Matt/projects/entrovae/')\n",
    "sys.path.append('/Users/Matt/projects/sgpvae/')\n",
    "\n",
    "import sgpvae\n",
    "import entrovae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.MNIST('../data', train=True, download=True,\n",
    "                               transform=transform)\n",
    "test_dataset = datasets.MNIST('../data', train=False,\n",
    "                              transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cls(model, train_loader, optimiser, epoch):\n",
    "    model.train()\n",
    "    batch_iter = tqdm.tqdm(enumerate(train_loader), desc='Batch')\n",
    "    for batch_idx, (x, y) in batch_iter:\n",
    "        optimiser.zero_grad()\n",
    "        loss, _ = model.nll(x, y)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(x), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "def test_cls(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            loss, output = model.nll(x, y)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "            \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = entrovae.classifiers.MNISTClassificationNet()\n",
    "cls_optimiser = optim.Adadelta(cls.parameters(), lr=1.0)\n",
    "cls_scheduler = StepLR(cls_optimiser, step_size=1, gamma=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "759a3fab1115497ea3b1f5e5d813c32e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Batch'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), maâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.314237\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.051367\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 1.590260\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.834733\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.843991\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.616237\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.447117\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.409173\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.381968\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.280283\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.098082\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.388107\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.375102\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.472000\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.318247\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.237400\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.226909\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.168259\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.121013\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.147906\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.174655\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.346931\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.209983\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.100823\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.223558\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.139476\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.146895\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.364617\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.172837\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.114454\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.214490\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.173509\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.306451\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.171635\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.249004\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.071891\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.142182\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.136018\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.245341\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.114164\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.135389\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.077102\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.187307\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.091353\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.174188\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.123079\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.086541\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.124788\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.192570\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.138229\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.114126\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.059373\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.172938\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.212122\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.170397\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.153402\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.064279\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.155915\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.077749\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.147003\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.220927\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.077559\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.094069\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.107586\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.149697\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.191186\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.159446\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.125164\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.099447\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.168887\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.054172\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.073178\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.113065\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.055134\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.064617\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.198001\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.134986\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.027550\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.094237\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.021499\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.130728\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.064077\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.065306\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.007825\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.111949\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.114858\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.093264\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.065070\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.099500\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.028596\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.079897\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.164266\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.129666\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.196334\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9821/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f94bdf57c72a4ad1a2b649c2151b1bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Batch'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), maâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.034331\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.019674\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.126029\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.061128\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.045753\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.088893\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.058639\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.040920\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.034352\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.019592\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.062951\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.122416\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.050896\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.152668\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.135594\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.327564\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.010959\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.038476\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.021379\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.027768\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.135029\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.058567\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-352ac99c7879>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_optimiser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtest_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcls_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-b399ff9a7408>\u001b[0m in \u001b[0;36mtrain_cls\u001b[0;34m(model, train_loader, optimiser, epoch)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/entrovae-env/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/entrovae-env/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 14+1):\n",
    "    train_cls(cls, train_loader, cls_optimiser, epoch)\n",
    "    test_cls(cls, test_loader)\n",
    "    cls_scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set GMMVAE datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "cls_output = torch.zeros(len(train_dataset), 10)\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (x, y) in enumerate(pred_loader):\n",
    "        cls_output[batch_idx*64:(batch_idx+1)*64] = cls(x).detach().exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMMVAEDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, cls_output):\n",
    "        self.x = x\n",
    "        self.cls_output = cls_output\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        return self.x[idx, ...], self.cls_output[idx]\n",
    "    \n",
    "gmmvae_dataset = GMMVAEDataset(train_dataset.data, cls_output)\n",
    "gmmvae_loader = torch.utils.data.DataLoader(gmmvae_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import autograd\n",
    "\n",
    "def train_gmmvae(model, loader, optimiser, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    batch_iter = tqdm.tqdm(enumerate(loader), desc='Batch')\n",
    "    \n",
    "    for batch_idx, (x, pi) in batch_iter:\n",
    "        optimiser.zero_grad()\n",
    "        \n",
    "        x = x.view(-1, 784).float() / 255\n",
    "        \n",
    "        loss = -model.elbo(x, pi)\n",
    "        loss.backward()\n",
    "        \n",
    "        for name, param in model.named_parameters():\n",
    "            if (param.grad != param.grad).any():\n",
    "                pdb.set_trace()\n",
    "                print('wtf')\n",
    "        \n",
    "        optimiser.step()\n",
    "        \n",
    "        train_loss += loss.item()        \n",
    "        batch_iter.set_postfix(loss=loss.item())\n",
    "            \n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 2\n",
    "x_dim = 784\n",
    "\n",
    "encoder = sgpvae.networks.LinearGaussian(x_dim, z_dim, [512, 256], min_sigma=1e-3)\n",
    "loglikelihood = entrovae.loglikelihoods.NNBernoulli(z_dim, x_dim, [256, 512])\n",
    "\n",
    "gmmvae_model = GMMVAE(encoder, loglikelihood, z_dim, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMMVAE training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aecf3f94f5842ed83c5eb1e2f3e422a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Batch'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), maâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====> Epoch: 1 Average loss: 2.8620\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e856d1ff05544e1c8cc74eb420b17ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Batch'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), maâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====> Epoch: 2 Average loss: 2.4977\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86bf559b2a0b435c9b3bfd1876c3251a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Batch'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), maâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====> Epoch: 3 Average loss: 2.4022\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c96d5c291b4c67ad661c2023f5e197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Batch'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), maâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-08af2e2a16d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgmmvae_optimiser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgmmvae_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_gmmvae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgmmvae_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmmvae_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmmvae_optimiser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-116-ac8b7c31e91b>\u001b[0m in \u001b[0;36mtrain_gmmvae\u001b[0;34m(model, loader, optimiser, epoch)\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wtf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/entrovae-env/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/entrovae-env/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'betas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    109\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/entrovae-env/lib/python3.8/site-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gmmvae_optimiser = optim.Adam(gmmvae_model.parameters())\n",
    "for epoch in range(1, 14+1):\n",
    "    train_gmmvae(gmmvae_model, gmmvae_loader, gmmvae_optimiser, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():            \n",
    "    sample = gmmvae_model.sample(num_samples=100)\n",
    "    \n",
    "    filename = './samples/gmmvae_sample'\n",
    "    \n",
    "    if os.path.exists(filename + '.png'):\n",
    "        i = 1\n",
    "        while os.path.exists(filename + '_' + str(i) + '.png'):\n",
    "            i += 1\n",
    "            \n",
    "        filename = filename + '_' + str(i) + '.png'\n",
    "        \n",
    "    else:\n",
    "        filename = filename + '.png'\n",
    "    \n",
    "    save_image(sample.view(100, 1, 28, 28), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.distributions.kl import kl_divergence\n",
    "\n",
    "\n",
    "class GMMVAE(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, loglikelihood, z_dim, k):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.loglikelihood = loglikelihood\n",
    "        self.z_dim = z_dim\n",
    "        self.k = k\n",
    "\n",
    "        # Initialise GMM parameters.\n",
    "        self.pz_y_mu = nn.Parameter(torch.randn((k, z_dim)),\n",
    "                                    requires_grad=True)\n",
    "        self.pz_y_logsigma = nn.Parameter(torch.zeros((k, z_dim)),\n",
    "                                          requires_grad=True)\n",
    "\n",
    "    def qz(self, x):\n",
    "        qz_mu, qz_sigma = self.encoder(x)\n",
    "        qz = Normal(qz_mu, qz_sigma)\n",
    "\n",
    "        return qz\n",
    "\n",
    "    def py_z(self, z, pi):\n",
    "        # Compute the marginal likelihood, p(z) = \\sum_k p(z|y)p(y).\n",
    "        pzy = torch.zeros_like(pi)\n",
    "        for k in range(self.k):\n",
    "            pz_y = Normal(self.pz_y_mu[k, :], self.pz_y_logsigma[k, :].exp())\n",
    "            pzy[:, k] = pz_y.log_prob(z).sum(1)\n",
    "            pzy[:, k] += pi[:, k].log()\n",
    "\n",
    "        pz = torch.logsumexp(pzy, dim=1)\n",
    "\n",
    "        # Compute the posterior p(y|z) = p(z, y) / p(z)\n",
    "        py_z = pzy - pz.unsqueeze(1)\n",
    "        py_z = Categorical(py_z.exp())\n",
    "\n",
    "        return py_z\n",
    "\n",
    "    def elbo(self, x, pi, num_samples=1):\n",
    "        \"\"\"Monte Carlo estimate of the evidence lower bound.\"\"\"\n",
    "        qz = self.qz(x)\n",
    "\n",
    "        # z_samples is shape (num_samples, batch, z_dim).\n",
    "        z_samples = qz.rsample((num_samples,))\n",
    "\n",
    "        log_px_z = 0\n",
    "        kl_y = 0\n",
    "        kl_z = 0\n",
    "        for z in z_samples:\n",
    "            log_px_z += self.loglikelihood(z, x).sum()\n",
    "\n",
    "            py_z = self.py_z(z, pi)\n",
    "            kl_y += kl_divergence(py_z, Categorical(pi)).sum()\n",
    "\n",
    "            for k in range(self.k):\n",
    "                pz_y = Normal(\n",
    "                    self.pz_y_mu[k, :].repeat(x.shape[0], 1), \n",
    "                    self.pz_y_logsigma[k, :].exp().repeat(x.shape[0], 1))\n",
    "                \n",
    "                kl_z_k = py_z.probs[:, k] * kl_divergence(qz, pz_y).sum(1)\n",
    "                kl_z += kl_z_k.sum()\n",
    "\n",
    "        log_px_z /= num_samples\n",
    "        kl_y /= num_samples\n",
    "        kl_z /= num_samples\n",
    "        elbo = (log_px_z - kl_y - kl_z) / x.shape[0]\n",
    "\n",
    "        return elbo\n",
    "\n",
    "    def sample(self, pi=None, num_samples=1):\n",
    "        if pi is None:\n",
    "            pi = torch.ones(self.k) / self.k\n",
    "\n",
    "        # Sample p(y).\n",
    "        py = Categorical(pi)\n",
    "        y = py.sample((num_samples,))\n",
    "\n",
    "        # Sample p(z|y).\n",
    "        pz_y = Normal(self.pz_y_mu[y, :], self.pz_y_logsigma[y, :].exp())\n",
    "        z = pz_y.sample()\n",
    "\n",
    "        # Sample p(x|z).\n",
    "        samples = self.loglikelihood.predict(z)\n",
    "\n",
    "        return samples\n",
    "\n",
    "    def predict_x(self, z):\n",
    "        x = self.loglikelihood.predict(z)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def reconstruct_x(self, x):\n",
    "        z, _ = self.encoder(x)\n",
    "        x_recon = self.loglikelihood.predict(z)\n",
    "\n",
    "        return x_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entrovae",
   "language": "python",
   "name": "entrovae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
